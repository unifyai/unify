
<a href="https://console.unify.ai/">
    <picture>
        <source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/unifyai/unifyai.github.io/refs/heads/main/img/logos/unify_logo_inverted_cropped.svg"/>
        <img class="dark-light" width="30%" src="https://raw.githubusercontent.com/unifyai/unifyai.github.io/refs/heads/main/img/logos/unify_logo_cropped.svg"/>
    </picture>
</a>

----

<a href="https://www.ycombinator.com/companies/unify">![Static Badge](https://img.shields.io/badge/Y%20Combinator-W23-orange)</a>
<a href="https://x.com/letsunifyai">![X (formerly Twitter) Follow](https://img.shields.io/twitter/follow/letsunifyai)</a>
<a href="https://discord.gg/sXyFF8tDtm"> ![Static Badge](https://img.shields.io/badge/Join_Discord-464646?&logo=discord&logoColor=5865F2) </a>

<div style="display: block;" align="center">
    <a href="https://console.unify.ai/">
        <img class="dark-light" width="100%" src="https://raw.githubusercontent.com/unifyai/unifyai.github.io/refs/heads/main/img/externally_linked/docs/line_group_dark.gif"/>
    </a>
</div>

**Fully hackable** LLMOps. Build *custom* interfaces for: logging, evals, guardrails, labelling, tracing, agents, human-in-the-loop, hyperparam sweeps, and anything else you can think of âœ¨

Just `unify.log` your data, and add an interface using the four building blocks:

1.  **tables** ğŸ”¢
2.  **views** ğŸ”
3. **plots** ğŸ“Š
4. **editor** ğŸ•¹ï¸ (coming soon)

Every LLM product has **unique** and **changing** requirements, as do the **users**. Your infra should reflect this!

We've tried to make Unify as **(a) simple**, **(b) modular** and **(c) hackable** as possible, so you can quickly probe, analyze, and iterate on the data that's important for **you**, your **product** and your **users** âš¡

## Quickstart

[Sign up](https://console.unify.ai/), `pip install unifyai`, run your first eval â¬‡ï¸, and then check out the logs in your first [interface](https://console.unify.ai) ğŸ“Š

```python
import unify
from random import randint, choice

# initialize project
unify.activate("Maths Assistant")

# build agent
client = unify.Unify("o3-mini@openai", traced=True)
client.set_system_message(
    "You are a helpful maths assistant, "
    "tasked with adding and subtracting integers."
)

# add test cases
qs = [
    f"{randint(0, 100)} {choice(['+', '-'])} {randint(0, 100)}"
    for i in range(10)
]

# define evaluator
@unify.traced
def evaluate_response(question: str, response: str) -> float:
    correct_answer = eval(question)
    try:
        response_int = int(
            "".join(
                [
                    c for c in response.split(" ")[-1]
                    if c.isdigit()
                ]
            ),
        )
        return float(correct_answer == response_int)
    except ValueError:
        return 0.

# define evaluation
@unify.traced
def evaluate(q: str):
    response = client.copy().generate(q)
    score = evaluate_response(q, response)
    unify.log(
        question=q,
        response=response,
        score=score
    )

# execute + log your evaluation
with unify.Experiment():
    unify.map(evaluate, qs)
```

Check out our [Quickstart Video](https://youtu.be/fl9SzsoCegw?si=MhQZDfNS6U-ZsVYc) for a guided walkthrough.

## Focus on your *product*, not the *LLM* ğŸ¯

Despite all of the hype, abstractions, and jargon, the *process* for building quality LLM apps is pretty simple.

```
create simplest possible agent ğŸ¤–
while True:
    create/expand unit tests (evals) ğŸ—‚ï¸
    while run(tests) failing: ğŸ§ª
        Analyze failures, understand the root cause ğŸ”
        Vary system prompt, in-context examples, tools etc. to rectify ğŸ”€
    Beta test with users, find more failures ğŸš¦
```

We've tried to strip away all of the excessive LLM jargon, so you can focus on your *product*, your *users*, and the *data* you care about, and *nothing else* ğŸ“ˆ

Unify takes inspiration from:
- [PostHog](https://posthog.com/) / [Grafana](https://grafana.com/) / [LogFire](https://pydantic.dev/logfire) for powerful observability ğŸ”¬
- [LangSmith](https://www.langchain.com/langsmith) / [BrainTrust](https://www.braintrust.dev/) / [Weave](https://wandb.ai/site/weave/) for LLM abstractions ğŸ¤–
- [Notion](https://www.notion.com/) / [Airtable](https://www.airtable.com/) for composability and versatility ğŸ§±

Whether you're technical or non-technical, we hope Unify can help you to rapidly build top-notch LLM apps, and to remain fully focused on your *product* (not the *LLM*).

## Learn More

Check out our [docs](https://docs.unify.ai/), and if you have any questions feel free to reach out to us on [discord](https://discord.com/invite/sXyFF8tDtm) ğŸ‘¾

Unify is under active development ğŸš§, feedback in all shapes/sizes is also very welcome! ğŸ™

Happy prompting! ğŸ§‘â€ğŸ’»
